{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de087137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: torch.Size([32, 3, 416, 416])\n",
      "Train Targets: [tensor([[0.0000, 0.6633, 0.3523, 0.3456, 0.3917],\n",
      "        [0.0000, 0.1480, 0.7422, 0.2402, 0.3882],\n",
      "        [3.0000, 0.5375, 0.7625, 0.4346, 0.2016],\n",
      "        [2.0000, 0.4091, 0.2468, 0.3659, 0.2248]]), tensor([[0.0000, 0.4022, 0.5041, 0.2478, 0.2341],\n",
      "        [3.0000, 0.4701, 0.2202, 0.2872, 0.1483],\n",
      "        [3.0000, 0.5705, 0.7265, 0.4371, 0.2410]]), tensor([], size=(0, 5)), tensor([[1.0000, 0.2789, 0.8210, 0.5121, 0.1611]]), tensor([[1.0000, 0.6328, 0.5805, 0.5184, 0.3129],\n",
      "        [1.0000, 0.6595, 0.5869, 0.1626, 0.5504]]), tensor([], size=(0, 5)), tensor([], size=(0, 5)), tensor([[0.0000, 0.8488, 0.3656, 0.3024, 0.2607],\n",
      "        [3.0000, 0.7992, 0.7213, 0.3532, 0.3395]]), tensor([[0.0000, 0.4130, 0.6813, 0.2643, 0.2688]]), tensor([[1.0000, 0.5775, 0.7735, 0.4435, 0.2955],\n",
      "        [0.0000, 0.4714, 0.5365, 0.1347, 0.2202],\n",
      "        [0.0000, 0.2802, 0.4930, 0.2020, 0.1703]]), tensor([[0.0000, 0.4701, 0.4589, 0.2490, 0.2016],\n",
      "        [0.0000, 0.4295, 0.2735, 0.2338, 0.1437]]), tensor([[0.0000, 0.4460, 0.6819, 0.1652, 0.2538],\n",
      "        [0.0000, 0.7255, 0.6773, 0.2287, 0.3094]]), tensor([[0.0000, 0.4142, 0.4687, 0.2135, 0.2167]]), tensor([], size=(0, 5)), tensor([[0.0000, 0.5552, 0.3807, 0.3452, 0.2605],\n",
      "        [0.0000, 0.4929, 0.4025, 0.2313, 0.2000]]), tensor([], size=(0, 5)), tensor([[1.0000, 0.7427, 0.5655, 0.2961, 0.0765],\n",
      "        [0.0000, 0.7827, 0.6194, 0.3050, 0.2723],\n",
      "        [1.0000, 0.6620, 0.5371, 0.1449, 0.5411],\n",
      "        [2.0000, 0.8424, 0.7057, 0.2160, 0.3523],\n",
      "        [2.0000, 0.7732, 0.6153, 0.3215, 0.1877]]), tensor([], size=(0, 5)), tensor([], size=(0, 5)), tensor([[0.0000, 0.1982, 0.4363, 0.2465, 0.1634],\n",
      "        [0.0000, 0.2090, 0.5232, 0.1741, 0.3024],\n",
      "        [1.0000, 0.3037, 0.8134, 0.6074, 0.3013]]), tensor([], size=(0, 5)), tensor([[0.0000, 0.8310, 0.5110, 0.2084, 0.2086],\n",
      "        [0.0000, 0.3259, 0.5591, 0.3189, 0.3071],\n",
      "        [1.0000, 0.8482, 0.7109, 0.3037, 0.5411]]), tensor([[0.0000, 0.3170, 0.3459, 0.1919, 0.2375],\n",
      "        [0.0000, 0.5121, 0.4867, 0.2211, 0.1831],\n",
      "        [1.0000, 0.3323, 0.3459, 0.1461, 0.4670],\n",
      "        [2.0000, 0.7084, 0.3644, 0.4485, 0.1425],\n",
      "        [2.0000, 0.3253, 0.4160, 0.2999, 0.2086]]), tensor([[1.0000, 0.7147, 0.3853, 0.3621, 0.2190],\n",
      "        [1.0000, 0.7732, 0.4264, 0.3545, 0.2619],\n",
      "        [1.0000, 0.7160, 0.4762, 0.5044, 0.4287],\n",
      "        [0.0000, 0.8081, 0.6506, 0.1042, 0.1773],\n",
      "        [0.0000, 0.9015, 0.7045, 0.0445, 0.1993]]), tensor([[0.0000, 0.8952, 0.4363, 0.1970, 0.3071],\n",
      "        [3.0000, 0.5248, 0.5435, 0.1271, 0.4056]]), tensor([], size=(0, 5)), tensor([], size=(0, 5)), tensor([], size=(0, 5)), tensor([], size=(0, 5)), tensor([], size=(0, 5)), tensor([[1.0000, 0.5928, 0.7671, 0.4790, 0.2225]]), tensor([], size=(0, 5))]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import get_dataloader, custom_collate_fn\n",
    "\n",
    "# We have to keep the code in another folder so that we can be able to parallelize the preprocessing jobs. Saves time. \n",
    "\n",
    "# =============================================================================\n",
    "# Adjust these paths according to your folder structure.\n",
    "# =============================================================================\n",
    "if __name__ == '__main__':\n",
    "    # Set this to your individual parent folder\n",
    "    base_dir = \"/Users/edgarsuritis/Downloads/FinalProjectData/\"\n",
    "    \n",
    "    # Use the CSV files in the easy split folder:\n",
    "    csv_train = os.path.join(base_dir, \"TestTrainSplits\", \"train_test_easy\", \"train.csv\")\n",
    "    csv_test  = os.path.join(base_dir, \"TestTrainSplits\", \"train_test_easy\", \"test.csv\")\n",
    "\n",
    "    # Additional smaller dataset splits\n",
    "    csv_james = os.path.join(base_dir, \"TestTrainSplits\", \"James.csv\")\n",
    "    csv_rashik = os.path.join(base_dir, \"TestTrainSplits\", \"Rashik.csv\")\n",
    "    \n",
    "    # Directory containing JPEG images.\n",
    "    images_dir = os.path.join(base_dir, \"JPEGImage\")\n",
    "    # Directory containing positive XML annotations.\n",
    "    annotations_dir = os.path.join(base_dir, \"positive-Annotation\")\n",
    "    \n",
    "    # DataLoaders for training and testing.\n",
    "    # Pass the custom collate function here:\n",
    "    train_loader = get_dataloader(csv_james, images_dir, annotations_dir, batch_size=32, train=True)\n",
    "    test_loader  = get_dataloader(csv_rashik, images_dir, annotations_dir, batch_size=32, train=False)\n",
    "    \n",
    "    # When creating the DataLoader inside get_dataloader, set the collate_fn parameter\n",
    "    # For example, modify get_dataloader to:\n",
    "    # return DataLoader(dataset, batch_size=batch_size, shuffle=train, num_workers=4, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    # For our testing, we can either modify get_dataloader() or wrap it here:\n",
    "    from torch.utils.data import DataLoader\n",
    "    # Reconstruct using our custom_collate_fn for demonstration:\n",
    "    train_loader = DataLoader(train_loader.dataset, batch_size=32, shuffle=True, num_workers=4, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    # Simple test: iterate through one batch.\n",
    "    for imgs, targets in train_loader:\n",
    "        print(\"Train Images shape:\", imgs.shape)  # Expected: [batch, 3, 416, 416]\n",
    "        print(\"Train Targets:\", targets)  # A list, each element a tensor of shape [N, 4] (or [N, 5] if you include classes)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
